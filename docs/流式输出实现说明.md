# 流式输出实现说明

## 一、流式输出架构

### 1.1 实现层次

流式输出在以下层次实现：

1. **LLM 客户端层** (`src/llm/http/generic.rs`)
   - `GenericHttpClient::complete_stream()` - 实现流式响应
   - 当前使用逐字符流式输出（获取完整响应后逐字符输出）
   - 未来将支持真正的 SSE 流式响应

2. **LLM 调用服务层** (`src/flow/services/llm_caller.rs`)
   - `LlmCaller::call_llm()` - 调用 LLM 并处理流式响应
   - 实时输出每个 chunk 的内容到标准输出
   - 自动 flush stdout 确保实时显示

3. **应用层** (`examples/food_analysis_app.rs`)
   - 显示流式输出的提示信息
   - 格式化最终结果输出

### 1.2 流式输出流程

```
LLM API 响应
    ↓
GenericHttpClient::complete_stream()
    ↓ (返回 LlmStream)
LlmCaller::call_llm()
    ↓ (逐 chunk 处理)
print!() + flush()
    ↓
标准输出（实时显示）
```

## 二、当前实现

### 2.1 流式输出格式

当 Agent 调用 LLM 时，输出格式如下：

```
[Agent Name] Starting response:
  [实时流式输出内容...]
[Agent Name] Response completed
```

### 2.2 应用层输出

在 `food_analysis_app.rs` 中：

1. **开始提示**
   ```
   🚀 开始执行食物分析工作流...
   💡 提示: LLM 响应将实时流式输出
   ================================================================================
   ```

2. **Agent 响应**（实时流式输出）
   ```
   [Image Preprocessor] Starting response:
     {"image_quality": "high", "format": "jpeg", ...}
   [Image Preprocessor] Response completed
   
   [Food Identifier] Starting response:
     {"foods": [...], ...}
   [Food Identifier] Response completed
   ```

3. **最终结果汇总**
   ```
   ================================================================================
   ✅ 工作流执行完成: food_analysis_flow
   
   📊 最终分析结果:
   ────────────────────────────────────────────────────────────────────────────
   
   🍽️  识别到的食物:
     1. apple (置信度: 95.0%)
   
   🔥 总卡路里: 75 kcal
   📦 食物数量: 1
   🎯 整体置信度: 95.0%
   ```

## 三、流式输出特性

### 3.1 实时性

- ✅ 每个字符/词实时输出，无需等待完整响应
- ✅ 使用 `print!()` + `flush()` 确保立即显示
- ✅ 支持多个 Agent 的顺序流式输出

### 3.2 格式化

- ✅ Agent 名称前缀标识
- ✅ 清晰的开始和结束标记
- ✅ 结构化的最终结果展示

### 3.3 用户体验

- ✅ 实时反馈，了解处理进度
- ✅ 清晰的输出分隔，易于阅读
- ✅ JSON 结果自动解析和格式化

## 四、技术实现

### 4.1 LlmStream 类型

```rust
pub type LlmStream = Pin<Box<dyn Stream<Item = Result<LlmStreamChunk>> + Send>>;

pub struct LlmStreamChunk {
    pub content: String,  // 当前 chunk 的内容
    pub done: bool,       // 是否完成
}
```

### 4.2 流式处理代码

在 `LlmCaller::call_llm()` 中：

```rust
let mut stream = llm_client.complete_stream(llm_request);
let mut full_response = String::new();

while let Some(chunk_result) = stream.next().await {
    match chunk_result {
        Ok(chunk) => {
            if !chunk.content.is_empty() {
                print!("{}", chunk.content);  // 实时输出
                std::io::Write::flush(&mut std::io::stdout())?;  // 立即刷新
                full_response.push_str(&chunk.content);
            }
            if chunk.done {
                break;
            }
        }
        Err(e) => return Err(e),
    }
}
```

## 五、运行示例

```bash
# 运行食物分析应用，查看流式输出
cargo run --example food_analysis_app --features openai-client
```

输出示例：

```
📷 使用图片: tests/test_food.jpg
✅ 图片已加载 (Base64 长度: 12345 字符)

🚀 开始执行食物分析工作流...

💡 提示: LLM 响应将实时流式输出

================================================================================

[Image Preprocessor] Starting response:
  {"image_quality": "high", "format": "jpeg", ...}
[Image Preprocessor] Response completed

[Food Identifier] Starting response:
  {"foods": [{"name": "apple", ...}], ...}
[Food Identifier] Response completed

[... 更多 Agent 响应 ...]

================================================================================

✅ 工作流执行完成: food_analysis_flow

📊 最终分析结果:
────────────────────────────────────────────────────────────────────────────

🍽️  识别到的食物:
  1. apple (置信度: 95.0%)

🔥 总卡路里: 75 kcal
📦 食物数量: 1
🎯 整体置信度: 95.0%
```

## 六、未来改进

### 6.1 真正的 SSE 流式响应

- 实现真正的 Server-Sent Events 流式响应
- 实时接收和解析 SSE 数据流
- 无需等待完整响应即可开始输出

### 6.2 更灵活的流式控制

- 支持配置流式输出的速度
- 支持暂停/恢复流式输出
- 支持流式输出的格式化选项

### 6.3 多 Agent 并行流式输出

- 支持多个 Agent 同时输出
- 使用不同颜色标识不同 Agent
- 支持流式输出的时间戳

